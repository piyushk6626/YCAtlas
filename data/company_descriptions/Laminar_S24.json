{
  "links": "https://www.ycombinator.com/companies/laminar",
  "name": "Laminar",
  "headline": "Open-source all-in-one platform for engineering AI products",
  "batch": "S24",
  "description": "Laminar is an open-source platform which provides observability, text analytics, evals and prompt chain management for AI agent.",
  "activity_status": "Active",
  "website": "https://www.lmnr.ai/",
  "founded_date": 2024.0,
  "team_size": 2.0,
  "location": "San Francisco",
  "group_partner": "Jared Friedman",
  "group_partner_yc": "https://www.ycombinator.com/people/jared-friedman",
  "company_linkedin": null,
  "company_twitter": null,
  "tags": "industry:aiops; industry:artificial-intelligence; industry:developer-tools; industry:saas; industry:b2b; location:san-francisco-bay-area",
  "founders": [
    {
      "name": "Robert Kim, Founder",
      "description": "Co-founder and CEO @ Laminar (lmnr.ai). Previously, I interned at Palantir where I built semantic search package which now powers many internal AI teams and worked on resource allocation engine at core infrastructure team. I also interned at Bloomberg where I scaled market tick processing pipeline by 10x to 10M ticks/s.",
      "linkedin": "https://www.linkedin.com/in/skull8888888/"
    },
    {
      "name": "Din Mailibay, Founder",
      "description": "Co-founder and CTO at Laminar (lmnr.ai). Previously, I have worked at Amazon for 2 years building and scaling critical payments infrastructure. Before that, I've spent a year creating ML infrastructure for a drug discovery biotech startup in Korea.",
      "linkedin": "https://www.linkedin.com/in/dinmukhamedm"
    }
  ],
  "status": true,
  "markdown": "raw_markdown='[![logo](https://www.lmnr.ai/_next/static/media/logo.b8a13d37.svg)](https://www.lmnr.ai/</>)\\n[Docs](https://www.lmnr.ai/<https:/docs.lmnr.ai>)[Pricing](https://www.lmnr.ai/</pricing>)[Blog](https://www.lmnr.ai/</blog>)[Discord](https://www.lmnr.ai/<https:/discord.gg/nNFUUDAKub>)[Star](https://www.lmnr.ai/<https:/github.com/lmnr-ai/lmnr>)[Book a demo](https://www.lmnr.ai/<https:/cal.com/robert-lmnr/demo>)\\n[Sign up](https://www.lmnr.ai/</sign-in>)\\n![](https://www.lmnr.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fnoise_resized.790fd46b.jpg&w=3840&q=100)\\nHow teams ship reliable AI products\\nLaminar is a unified open-source platform for tracing, evaluating, and labeling LLM products.\\n[Get started](https://www.lmnr.ai/</projects>)[Read the docs](https://www.lmnr.ai/<https:/docs.lmnr.ai>)\\nBacked by![backed by Y Combinator](https://www.lmnr.ai/_next/static/media/yc.9ecdcfc7.svg)\\nTeams that ship better LLM products with Laminar\\n[![Clarum](https://www.lmnr.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fclarum.e1d31867.png&w=3840&q=75)](https://www.lmnr.ai/<https:/clarum.ai>)[![Remo](https://www.lmnr.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fremo.094883a6.avif&w=1080&q=75)](https://www.lmnr.ai/<https:/getremo.ai>)[![Saturn](https://www.lmnr.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fsaturn.820a2538.png&w=640&q=75)](https://www.lmnr.ai/<https:/saturnos.com>)\\nI can attest to it being the only reliable and performant LLM monitoring platform I\\'ve tried. Founding team is great to talk to and super responsive.\\n![Clarum](https://www.lmnr.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fclarum.e1d31867.png&w=3840&q=75)\\nTommy He\\nCTO, Clarum\\nLaminar\\'s evals help us maintain high accuracy while moving fast, and their team is incredibly responsive. We now use them for every LLM based feature we build.\\n![Remo](https://www.lmnr.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fremo.094883a6.avif&w=1080&q=75)\\nHashim Rehman\\nCTO, Remo\\nLaminar\\'s tracing is genuinely great. So much better than the others I\\'ve tried.\\n![Saturn](https://www.lmnr.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fsaturn.820a2538.png&w=640&q=75)\\nMichael Ettlinger\\nCTO, Saturn\\n![](https://www.lmnr.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fnoise1_resized.e944463c.jpg&w=3840&q=100)\\nTraceEvaluateLabel\\n# Trace\\nTracing your LLM application provides visibility into every execution step while collecting valuable data for evaluations, few-shot examples, and fine-tuning. With Laminar, you can start tracing with just 2 lines of code.\\n[Start tracing your LLM app](https://www.lmnr.ai/<https:/docs.lmnr.ai/tracing/introduction>)\\nTypeScriptPython\\n```\\nimport{Laminar, observe }from\\'@lmnr-ai/lmnr\\';\\n// automatically traces common LLM frameworks and SDKsLaminar.initialize({projectApiKey:\"...\"});\\n// you can also manually trace any functionconst myFunction =observe({name:\\'myFunc\\'},async()=>{...})\\n```\\n\\n![Trace](https://www.lmnr.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftraces.35cde1e6.png&w=3840&q=75)\\n# [Effortless ObservabilityAdd 2 lines of code to trace all LLM calls and traces. Traces are sent in the background via gRPC with minimal performance and latency overhead.Start tracing ![Tracing visualization](https://www.lmnr.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fsmall-trace.9ac24f8a.png&w=3840&q=75)](https://www.lmnr.ai/<https:/docs.lmnr.ai/tracing/introduction>)\\n### [Online evaluationsSetup LLM or Python online evaluators to process each received span. Evaluators automatically label spans, which is more scalable than human labeling.Setup online evaluations ![Online evaluations](https://www.lmnr.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fonline-evals.f1a949e9.png&w=3840&q=75)](https://www.lmnr.ai/<https:/docs.lmnr.ai/evaluations/online-evaluations>)\\n### [Dynamic few-shot examples to improve promptsBuild datasets from traces for evaluations, fine-tuning and prompt engineering. Enhance prompts by retrieving semantically similar examples from indexed datasets.Create a dataset ![Dataset visualization](https://www.lmnr.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fdataset.db837ba8.png&w=3840&q=75)](https://www.lmnr.ai/<https:/docs.lmnr.ai/datasets/introduction>)\\n### [Serverless LLM pipelinesOur pipeline builder is an incredible prototyping tool. It lets you quickly build and iterate on both simple prompts and complex LLM chains. After thatDeploy LLM pipeline ![Prompt Chains visualization](https://www.lmnr.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2FMoA.de876642.png&w=3840&q=75)](https://www.lmnr.ai/<https:/docs.lmnr.ai/pipeline/introduction>)\\n### [Fully open-sourceLaminar is fully open-source and easy to self-host. Get started with just a few commands.Self-host Laminar ](https://www.lmnr.ai/<https:/github.com/lmnr-ai/lmnr>)\\nContact us[GitHub](https://www.lmnr.ai/<https:/github.com/lmnr-ai/lmnr>)[Join Discord](https://www.lmnr.ai/<https:/discord.gg/nNFUUDAKub>)[Privacy policy](https://www.lmnr.ai/<https:/docs.lmnr.ai/policies/privacy-policy>)[Terms of service](https://www.lmnr.ai/<https:/docs.lmnr.ai/policies/terms-of-service>)[Status](https://www.lmnr.ai/<https:/status.lmnr.ai>)\\n' markdown_with_citations='![logo⟨1⟩](https://www.lmnr.ai/</>)\\nDocs⟨2⟩Pricing⟨3⟩Blog⟨4⟩Discord⟨5⟩Star⟨6⟩Book a demo⟨7⟩\\nSign up⟨8⟩\\n![](https://www.lmnr.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fnoise_resized.790fd46b.jpg&w=3840&q=100)\\nHow teams ship reliable AI products\\nLaminar is a unified open-source platform for tracing, evaluating, and labeling LLM products.\\nGet started⟨9⟩Read the docs⟨2⟩\\nBacked by![backed by Y Combinator⟨10⟩]\\nTeams that ship better LLM products with Laminar\\n![Clarum⟨11⟩](https://www.lmnr.ai/<https:/clarum.ai>)![Remo⟨12⟩](https://www.lmnr.ai/<https:/getremo.ai>)![Saturn⟨13⟩](https://www.lmnr.ai/<https:/saturnos.com>)\\nI can attest to it being the only reliable and performant LLM monitoring platform I\\'ve tried. Founding team is great to talk to and super responsive.\\n![Clarum⟨11⟩]\\nTommy He\\nCTO, Clarum\\nLaminar\\'s evals help us maintain high accuracy while moving fast, and their team is incredibly responsive. We now use them for every LLM based feature we build.\\n![Remo⟨12⟩]\\nHashim Rehman\\nCTO, Remo\\nLaminar\\'s tracing is genuinely great. So much better than the others I\\'ve tried.\\n![Saturn⟨13⟩]\\nMichael Ettlinger\\nCTO, Saturn\\n![](https://www.lmnr.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fnoise1_resized.e944463c.jpg&w=3840&q=100)\\nTraceEvaluateLabel\\n# Trace\\nTracing your LLM application provides visibility into every execution step while collecting valuable data for evaluations, few-shot examples, and fine-tuning. With Laminar, you can start tracing with just 2 lines of code.\\nStart tracing your LLM app⟨14⟩\\nTypeScriptPython\\n```\\nimport{Laminar, observe }from\\'@lmnr-ai/lmnr\\';\\n// automatically traces common LLM frameworks and SDKsLaminar.initialize({projectApiKey:\"...\"});\\n// you can also manually trace any functionconst myFunction =observe({name:\\'myFunc\\'},async()=>{...})\\n```\\n\\n![Trace⟨15⟩]\\n# Effortless ObservabilityAdd 2 lines of code to trace all LLM calls and traces. Traces are sent in the background via gRPC with minimal performance and latency overhead.Start tracing ![Tracing visualization⟨16⟩](https://www.lmnr.ai/<https:/docs.lmnr.ai/tracing/introduction>)\\n### Online evaluationsSetup LLM or Python online evaluators to process each received span. Evaluators automatically label spans, which is more scalable than human labeling.Setup online evaluations ![Online evaluations⟨17⟩](https://www.lmnr.ai/<https:/docs.lmnr.ai/evaluations/online-evaluations>)\\n### Dynamic few-shot examples to improve promptsBuild datasets from traces for evaluations, fine-tuning and prompt engineering. Enhance prompts by retrieving semantically similar examples from indexed datasets.Create a dataset ![Dataset visualization⟨18⟩](https://www.lmnr.ai/<https:/docs.lmnr.ai/datasets/introduction>)\\n### Serverless LLM pipelinesOur pipeline builder is an incredible prototyping tool. It lets you quickly build and iterate on both simple prompts and complex LLM chains. After thatDeploy LLM pipeline ![Prompt Chains visualization⟨19⟩](https://www.lmnr.ai/<https:/docs.lmnr.ai/pipeline/introduction>)\\n### Fully open-sourceLaminar is fully open-source and easy to self-host. Get started with just a few commands.Self-host Laminar ⟨6⟩\\nContact usGitHub⟨6⟩Join Discord⟨5⟩Privacy policy⟨20⟩Terms of service⟨21⟩Status⟨22⟩\\n' references_markdown='\\n\\n## References\\n\\n⟨1⟩ https://www.lmnr.ai/_next/static/media/logo.b8a13d37.svg: ![logo\\n⟨2⟩ https://www.lmnr.ai/<https:/docs.lmnr.ai>: Docs\\n⟨3⟩ https://www.lmnr.ai/</pricing>: Pricing\\n⟨4⟩ https://www.lmnr.ai/</blog>: Blog\\n⟨5⟩ https://www.lmnr.ai/<https:/discord.gg/nNFUUDAKub>: Discord\\n⟨6⟩ https://www.lmnr.ai/<https:/github.com/lmnr-ai/lmnr>: Star\\n⟨7⟩ https://www.lmnr.ai/<https:/cal.com/robert-lmnr/demo>: Book a demo\\n⟨8⟩ https://www.lmnr.ai/</sign-in>: Sign up\\n⟨9⟩ https://www.lmnr.ai/</projects>: Get started\\n⟨10⟩ https://www.lmnr.ai/_next/static/media/yc.9ecdcfc7.svg: backed by Y Combinator\\n⟨11⟩ https://www.lmnr.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fclarum.e1d31867.png&w=3840&q=75: ![Clarum\\n⟨12⟩ https://www.lmnr.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fremo.094883a6.avif&w=1080&q=75: ![Remo\\n⟨13⟩ https://www.lmnr.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fsaturn.820a2538.png&w=640&q=75: ![Saturn\\n⟨14⟩ https://www.lmnr.ai/<https:/docs.lmnr.ai/tracing/introduction>: Start tracing your LLM app\\n⟨15⟩ https://www.lmnr.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftraces.35cde1e6.png&w=3840&q=75: Trace\\n⟨16⟩ https://www.lmnr.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fsmall-trace.9ac24f8a.png&w=3840&q=75: Effortless ObservabilityAdd 2 lines of code to trace all LLM calls and traces. Traces are sent in the background via gRPC with minimal performance and latency overhead.Start tracing ![Tracing visualization\\n⟨17⟩ https://www.lmnr.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fonline-evals.f1a949e9.png&w=3840&q=75: Online evaluationsSetup LLM or Python online evaluators to process each received span. Evaluators automatically label spans, which is more scalable than human labeling.Setup online evaluations ![Online evaluations\\n⟨18⟩ https://www.lmnr.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fdataset.db837ba8.png&w=3840&q=75: Dynamic few-shot examples to improve promptsBuild datasets from traces for evaluations, fine-tuning and prompt engineering. Enhance prompts by retrieving semantically similar examples from indexed datasets.Create a dataset ![Dataset visualization\\n⟨19⟩ https://www.lmnr.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2FMoA.de876642.png&w=3840&q=75: Serverless LLM pipelinesOur pipeline builder is an incredible prototyping tool. It lets you quickly build and iterate on both simple prompts and complex LLM chains. After thatDeploy LLM pipeline ![Prompt Chains visualization\\n⟨20⟩ https://www.lmnr.ai/<https:/docs.lmnr.ai/policies/privacy-policy>: Privacy policy\\n⟨21⟩ https://www.lmnr.ai/<https:/docs.lmnr.ai/policies/terms-of-service>: Terms of service\\n⟨22⟩ https://www.lmnr.ai/<https:/status.lmnr.ai>: Status\\n' fit_markdown='' fit_html=''",
  "generated_description": "**Company Overview: Laminar**\n\n**Founded:** 2024  \n**Location:** San Francisco  \n**Team Size:** 2 employees  \n**Y Combinator Batch:** S24  \n**Website:** [lmnr.ai](https://www.lmnr.ai)  \n\n**Mission:** Laminar is on a mission to be the open-source, all-in-one platform for engineering AI products, aiming to streamline the development and management of AI systems.\n\n---\n\n**What They Do:**\n\nInitially, Laminar started as a robust platform focused on observability, text analytics, evaluations, and prompt chain management for AI applications. They are carving out a niche in the AI landscape by offering tools that enhance the way teams trace, evaluate, and label AI models, specifically in the realm of large language models (LLMs).\n\n**Key Features:**\n\n- **Tracing:** Laminar allows developers to easily trace their LLM applications, providing clarity on each execution step. With just two lines of code, teams can collect valuable data for evaluations and fine-tuning.\n  \n- **Online Evaluations:** Teams can set up LLM or Python online evaluators to label spans automatically, making it easier to maintain accuracy without heavy reliance on human input.\n  \n- **Dynamic Few-shot Examples:** Users can build datasets from traces, enhancing their prompts by retrieving similar examples to fine-tune their models intelligently.\n  \n- **Serverless LLM Pipelines:** The platform offers a tool for building and iterating on both basic and complex LLM prompts, facilitating rapid prototyping and deployment.\n\n- **Fully Open-source:** Laminar is designed to be fully open-source, allowing easy self-hosting and encouraging community contributions.\n\n---\n\n**Market Positioning:**\n\nLaminar tags itself under categories like AIOps, artificial intelligence, developer tools, SaaS, and B2B, effectively positioning itself as a versatile tool for AI product development. It's already making waves among companies looking for reliable LLM solutions.\n\n**Testimonials:**\n\n- **Tommy He, CTO of Clarum:** \"It's the only reliable and performant LLM monitoring platform I’ve tried.\"\n\n- **Hashim Rehman, CTO of Remo:** \"Laminar's evals help maintain high accuracy while moving fast.\"\n\n- **Michael Ettlinger, CTO of Saturn:** \"Their tracing is genuinely great; so much better than the others I've tried.\"\n\n---\n\n**Why it Matters:**\n\nIn an era where AI is increasingly incorporated into business operations, tools that enhance the development lifecycle are paramount. Laminar stands out by providing an open-source solution that simplifies the complexities of AI engineering, making it accessible for smaller teams and startups while still catering to larger enterprises looking for efficient solutions. Their progress is worth watching as they continue to evolve in the rapidly expanding AI field."
}