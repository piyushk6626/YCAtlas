{
  "links": "https://www.ycombinator.com/companies/hatchet-2",
  "name": "Hatchet",
  "headline": "Background task orchestration and visibility",
  "batch": "W24",
  "description": "Hatchet abstracts away the infrastructure for managing task queues and message brokers, so you can focus on writing your background task and workflow logic. With Hatchet, you can run slow OpenAI requests in the background with async tasks, chain complex tasks together into workflows, and set retries and timeouts to recover from failure.",
  "activity_status": "Active",
  "website": "https://hatchet.run",
  "founded_date": 2023.0,
  "team_size": 2.0,
  "location": "New York",
  "group_partner": "Dalton Caldwell",
  "group_partner_yc": "https://www.ycombinator.com/people/dalton-caldwell",
  "company_linkedin": null,
  "company_twitter": null,
  "tags": "industry:developer-tools; industry:open-source; industry:infrastructure; location:new-york",
  "founders": [
    {
      "name": "Alexander Belanger, Founder",
      "description": "Co-founder & CEO at Hatchet (W24), previously co-founder & CTO at Porter (S20). M.S. in Physics, B.A. in Physics and Computer Science from the University of Pennsylvania. \n\nAlways happy to chat anything devtools, OSS, infrastructure!",
      "linkedin": "https://linkedin.com/in/alexander-belanger-aa3974135"
    },
    {
      "name": "Gabe Ruttner, Founder",
      "description": "Co-founder & CTO at Hatchet (W24), previously co-founder & CTO at ClearMix (S20). Masters in CS/AI from Cornell. Always game to chat anything dev tools, OSS, AI Architecture!",
      "linkedin": "https://linkedin.com/in/gruttner"
    }
  ],
  "status": true,
  "markdown": "raw_markdown='[ Hatchet is fully open-source. Star us on Github](https://hatchet.run/<https:/github.com/hatchet-dev/hatchet>)\\n[![Hatchet](https://hatchet.run/_next/static/media/hatchet-logo.fcf6ba54.svg)](https://hatchet.run/</>)\\n  * [Product](https://hatchet.run/</>)\\n  * [Pricing](https://hatchet.run/</pricing>)\\n  * [Documentation](https://hatchet.run/<https:/docs.hatchet.run>)\\n\\n\\n    * [](https://hatchet.run/<https:/twitter.com/hatchet_dev>)\\n    * [](https://hatchet.run/<https:/discord.gg/ZMeUafwH89>)\\n    * [](https://hatchet.run/<https:/github.com/hatchet-dev/hatchet>)\\n  * [Sign In](https://hatchet.run/<https:/cloud.onhatchet.run/auth/login>)[Get StartedGet Started](https://hatchet.run/<https:/cloud.onhatchet.run/auth/register>)\\n\\n\\nMenu\\n  * [Product](https://hatchet.run/</>)\\n  * [Pricing](https://hatchet.run/</pricing>)\\n  * [Documentation](https://hatchet.run/<https:/docs.hatchet.run>)\\n    * [](https://hatchet.run/<https:/twitter.com/hatchet_dev>)\\n    * [](https://hatchet.run/<https:/discord.gg/ZMeUafwH89>)\\n    * [](https://hatchet.run/<https:/github.com/hatchet-dev/hatchet>)\\n\\n\\n# The Distributed Task Queue for More Resilient Web Applications\\nHatchet is a distributed, fault-tolerant task queue which replaces traditional message brokers and pub/sub systems - built to solve problems like concurrency, fairness, and durability.\\n[Try Hatchet Cloud](https://hatchet.run/<https:/cloud.onhatchet.run/auth/register>)[Meet with a Founder ](https://hatchet.run/</office-hours>)\\nBacked by ![YCombinator](https://hatchet.run/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fyc.6a2a28a4.png&w=3840&q=75)\\nUse-cases\\n### Hatchet handles common scaling challenges.\\nFairness for Generative AI\\nDon\\'t let busy users overwhelm your system. Hatchet lets you distribute requests to your workers fairly with configurable policies.\\n[Learn More ->](https://hatchet.run/<https:/docs.hatchet.run/home/features/concurrency/round-robin>)\\nBatch Processing of Documents\\nHatchet can handle large-scale batch processing of documents, images, and other data and resume mid-job on failure.\\n[Learn More ->](https://hatchet.run/<https:/docs.hatchet.run/home/features/child-workflows#scattergather-workflows>)\\nWorkflow Orchestration for Multi-Modal Systems\\nHatchet can handle orchestrating multi-modal inputs and outputs, with full DAG-style execution.\\n[Learn More ->](https://hatchet.run/<https:/docs.hatchet.run/home/basics/workflows>)\\nCorrectness for Event-Based Architectures\\nRespond to external events or internal events within your system and replay events automatically.\\n## Building Blocks for Scale.\\nHatchet is engineered for the scaling challenges you have today and the ones you\\'ll have tomorrow.\\n### Low Latency, High Throughput Scheduling.\\nHatchet is built on a low-latency queue (25ms average start), perfectly balancing real-time interaction capabilities with the reliability required for mission-critical tasks.\\n02 PM03 PM04 PM05 PM06 PM07 PM08 PM\\n### Concurrency, Fairness, and Rate limiting.\\nEnable FIFO, LIFO, Round Robin, and Priority Queues with built-in strategies to avoid common pitfalls.\\n[View All Strategies ->](https://hatchet.run/<https:/docs.hatchet.run/home/features/concurrency/overview>)\\n### Architected for Resiliency.\\nCustomizable retry policies and built-in error handling to recover from transient failures.\\n![Feature 03](https://hatchet.run/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fresilience.157b83bc.png&w=750&q=75)\\n####  Observability\\nAll of your runs are fully searchable, allowing you to quickly identify issues. We stream logs, track latency, error rates, or custom metrics in your run.\\n[Learn More ->](https://hatchet.run/<https:/docs.hatchet.run/home/features/errors-and-logging>)\\n#### (Practical) Durable Execution\\nReplay events and manually pick up execution from specific steps in your workflow.\\n[Learn More ->](https://hatchet.run/<https:/docs.hatchet.run/home/features/durable-execution>)\\n#### Cron\\nSet recurring schedules for functions runs to execute.\\n[Learn More ->](https://hatchet.run/<https:/docs.hatchet.run/home/features/triggering-runs/cron-trigger>)\\n####  One-Time Scheduling\\nSchedule a function run to execute at a specific time and date in the future.\\n[Learn More ->](https://hatchet.run/<https:/docs.hatchet.run/home/features/triggering-runs/schedule-trigger>)\\n#### Spike Protection\\nSmooth out spikes in traffic and only execute what your system can handle.\\n[Learn More ->](https://hatchet.run/<https:/docs.hatchet.run/home/features/concurrency/overview#setting-concurrency-on-workers>)\\n#### Incremental Streaming\\nSubscribe to updates as your functions progress in the background worker.\\n[Learn More ->](https://hatchet.run/<https:/docs.hatchet.run/home/features/streaming>)\\n## Hatchet Supports your Stack.\\nHatchet offers open-source declarative SDKs to define your functions in Python, Typescript, and Go so you can develop using the right tools for the job and always have the flexibility to implement the latest technologies.\\nSupported Technologies\\n#### Easy to get started...\\n## 1. Register your function\\nRegister your function with Hatchet using the Hatchet SDK for your preferred language.\\nPython \\n9\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n›\\n⌄\\n⌄\\n# Define your workflow by decorating a class with the @hatchet workflow decorator\\n@hatchet.workflow(on_events=[\"simple:create\"])\\nclass SimpleWorkflow:\\n# Register your steps by decorating a method with the @hatchet step decorator\\n@hatchet.step()\\ndef step1(self, context: Context):\\nprint(\"executed step1\")\\nreturn {\"results\": \"step1 data\"}\\n## 2. Start your Hatchet worker\\nStart your Hatchet worker to start listening for events.\\nPython \\n9\\n1\\n2\\n3\\n4\\n5\\n6\\n›\\n# Instantiate the worker\\nworker = hatchet.worker(\\'example-worker\\')\\n# Register the workflow with the worker\\nworker.register_workflow(SimpleWorkflow())\\n# Start the worker and begin listening for events\\nworker.start()\\n## 3. Run your function\\nFrom your API application, run your function by pushing an event to Hatchet.\\nPython \\n9\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n›\\n⌄\\n# Push an event to the worker to run the workflow\\nhatchet.client.event.push(\\n\"simple:create\",\\n{\\n\"test\": \"test\"\\n}\\n)\\n[Read the Docs](https://hatchet.run/<https:/docs.hatchet.run/>)[ View the Source ](https://hatchet.run/<https:/github.com/hatchet-dev/hatchet>)\\n## ...with room to grow\\nOur SDKs are designed to easily add steps to your workflow with complex parent relationships defined as a Directed Acyclic Graph (DAG).\\nDurable workflows that can resume on fail\\nRun steps on specialized infra to reduce cost\\nRetries, streaming, and more...\\n[View Python Examples](https://hatchet.run/<https:/github.com/hatchet-dev/hatchet-python-quickstart/tree/main/simple-examples/src/dag>)\\n### Built forEnterprise Scale\\nBest-in-class security, privacy, and scalability.\\n  * Highly scalable architecture.\\n  * Support from infra experts.\\n  * Industry leading security. [Learn more →](https://hatchet.run/</security>)\\n\\n\\nDistributed Systems Made Easy\\n## Talk to one of our Infra Experts\\nGet started by scheduling time to talk to the Hatchet team or joining our community to better understand how Hatchet can help you with your use case.\\n[Book Office Hours](https://hatchet.run/</office-hours>)[Join our Community ](https://hatchet.run/<https:/discord.gg/ZMeUafwH89>)\\n[![Hatchet](https://hatchet.run/_next/static/media/hatchet-logo.fcf6ba54.svg)](https://hatchet.run/</>)\\n© Hatchet Technologies, Inc. - All rights reserved.\\n  * [](https://hatchet.run/<https:/twitter.com/hatchet_dev>)\\n  * [](https://hatchet.run/<https:/discord.gg/ZMeUafwH89>)\\n  * [](https://hatchet.run/<https:/github.com/hatchet-dev/hatchet>)\\n\\n\\n###### About\\n  * [Features](https://hatchet.run/</>)\\n  * [Pricing & Plans](https://hatchet.run/</pricing>)\\n  * [Documentation](https://hatchet.run/<https:/docs.hatchet.run/>)\\n  * [Jobs 1](https://hatchet.run/<https:/www.ycombinator.com/companies/hatchet-2>)\\n\\n\\n###### Community\\n  * [GitHub](https://hatchet.run/<https:/github.com/hatchet-dev/hatchet>)\\n  * [Discord](https://hatchet.run/<https:/discord.gg/ZMeUafwH89>)\\n  * Email\\n\\n\\n###### Policies & Legal\\n  * [Security](https://hatchet.run/</security>)\\n  * [Terms & Conditions](https://hatchet.run/<https:/www.iubenda.com/terms-and-conditions/76608149>)\\n  * [Privacy policy](https://hatchet.run/<https:/www.iubenda.com/privacy-policy/76608149>)\\n  * [Cookie Policy](https://hatchet.run/<https:/www.iubenda.com/privacy-policy/76608149/cookie-policy>)\\n\\n\\n08\\n' markdown_with_citations=' Hatchet is fully open-source. Star us on Github⟨1⟩\\n![Hatchet⟨2⟩](https://hatchet.run/</>)\\n  * Product⟨3⟩\\n  * Pricing⟨4⟩\\n  * Documentation⟨5⟩\\n\\n\\n    * [](https://hatchet.run/<https:/twitter.com/hatchet_dev>)\\n    * [](https://hatchet.run/<https:/discord.gg/ZMeUafwH89>)\\n    * [](https://hatchet.run/<https:/github.com/hatchet-dev/hatchet>)\\n  * Sign In⟨6⟩Get StartedGet Started⟨7⟩\\n\\n\\nMenu\\n  * Product⟨3⟩\\n  * Pricing⟨4⟩\\n  * Documentation⟨5⟩\\n    * [](https://hatchet.run/<https:/twitter.com/hatchet_dev>)\\n    * [](https://hatchet.run/<https:/discord.gg/ZMeUafwH89>)\\n    * [](https://hatchet.run/<https:/github.com/hatchet-dev/hatchet>)\\n\\n\\n# The Distributed Task Queue for More Resilient Web Applications\\nHatchet is a distributed, fault-tolerant task queue which replaces traditional message brokers and pub/sub systems - built to solve problems like concurrency, fairness, and durability.\\nTry Hatchet Cloud⟨7⟩Meet with a Founder ⟨8⟩\\nBacked by ![YCombinator⟨9⟩]\\nUse-cases\\n### Hatchet handles common scaling challenges.\\nFairness for Generative AI\\nDon\\'t let busy users overwhelm your system. Hatchet lets you distribute requests to your workers fairly with configurable policies.\\nLearn More ->⟨10⟩\\nBatch Processing of Documents\\nHatchet can handle large-scale batch processing of documents, images, and other data and resume mid-job on failure.\\nLearn More ->⟨11⟩\\nWorkflow Orchestration for Multi-Modal Systems\\nHatchet can handle orchestrating multi-modal inputs and outputs, with full DAG-style execution.\\nLearn More ->⟨12⟩\\nCorrectness for Event-Based Architectures\\nRespond to external events or internal events within your system and replay events automatically.\\n## Building Blocks for Scale.\\nHatchet is engineered for the scaling challenges you have today and the ones you\\'ll have tomorrow.\\n### Low Latency, High Throughput Scheduling.\\nHatchet is built on a low-latency queue (25ms average start), perfectly balancing real-time interaction capabilities with the reliability required for mission-critical tasks.\\n02 PM03 PM04 PM05 PM06 PM07 PM08 PM\\n### Concurrency, Fairness, and Rate limiting.\\nEnable FIFO, LIFO, Round Robin, and Priority Queues with built-in strategies to avoid common pitfalls.\\nView All Strategies ->⟨13⟩\\n### Architected for Resiliency.\\nCustomizable retry policies and built-in error handling to recover from transient failures.\\n![Feature 03⟨14⟩]\\n####  Observability\\nAll of your runs are fully searchable, allowing you to quickly identify issues. We stream logs, track latency, error rates, or custom metrics in your run.\\nLearn More ->⟨15⟩\\n#### (Practical) Durable Execution\\nReplay events and manually pick up execution from specific steps in your workflow.\\nLearn More ->⟨16⟩\\n#### Cron\\nSet recurring schedules for functions runs to execute.\\nLearn More ->⟨17⟩\\n####  One-Time Scheduling\\nSchedule a function run to execute at a specific time and date in the future.\\nLearn More ->⟨18⟩\\n#### Spike Protection\\nSmooth out spikes in traffic and only execute what your system can handle.\\nLearn More ->⟨19⟩\\n#### Incremental Streaming\\nSubscribe to updates as your functions progress in the background worker.\\nLearn More ->⟨20⟩\\n## Hatchet Supports your Stack.\\nHatchet offers open-source declarative SDKs to define your functions in Python, Typescript, and Go so you can develop using the right tools for the job and always have the flexibility to implement the latest technologies.\\nSupported Technologies\\n#### Easy to get started...\\n## 1. Register your function\\nRegister your function with Hatchet using the Hatchet SDK for your preferred language.\\nPython \\n9\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n›\\n⌄\\n⌄\\n# Define your workflow by decorating a class with the @hatchet workflow decorator\\n@hatchet.workflow(on_events=[\"simple:create\"])\\nclass SimpleWorkflow:\\n# Register your steps by decorating a method with the @hatchet step decorator\\n@hatchet.step()\\ndef step1(self, context: Context):\\nprint(\"executed step1\")\\nreturn {\"results\": \"step1 data\"}\\n## 2. Start your Hatchet worker\\nStart your Hatchet worker to start listening for events.\\nPython \\n9\\n1\\n2\\n3\\n4\\n5\\n6\\n›\\n# Instantiate the worker\\nworker = hatchet.worker(\\'example-worker\\')\\n# Register the workflow with the worker\\nworker.register_workflow(SimpleWorkflow())\\n# Start the worker and begin listening for events\\nworker.start()\\n## 3. Run your function\\nFrom your API application, run your function by pushing an event to Hatchet.\\nPython \\n9\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n›\\n⌄\\n# Push an event to the worker to run the workflow\\nhatchet.client.event.push(\\n\"simple:create\",\\n{\\n\"test\": \"test\"\\n}\\n)\\nRead the Docs⟨21⟩ View the Source ⟨1⟩\\n## ...with room to grow\\nOur SDKs are designed to easily add steps to your workflow with complex parent relationships defined as a Directed Acyclic Graph (DAG).\\nDurable workflows that can resume on fail\\nRun steps on specialized infra to reduce cost\\nRetries, streaming, and more...\\nView Python Examples⟨22⟩\\n### Built forEnterprise Scale\\nBest-in-class security, privacy, and scalability.\\n  * Highly scalable architecture.\\n  * Support from infra experts.\\n  * Industry leading security. Learn more →⟨23⟩\\n\\n\\nDistributed Systems Made Easy\\n## Talk to one of our Infra Experts\\nGet started by scheduling time to talk to the Hatchet team or joining our community to better understand how Hatchet can help you with your use case.\\nBook Office Hours⟨8⟩Join our Community ⟨24⟩\\n![Hatchet⟨2⟩](https://hatchet.run/</>)\\n© Hatchet Technologies, Inc. - All rights reserved.\\n  * [](https://hatchet.run/<https:/twitter.com/hatchet_dev>)\\n  * [](https://hatchet.run/<https:/discord.gg/ZMeUafwH89>)\\n  * [](https://hatchet.run/<https:/github.com/hatchet-dev/hatchet>)\\n\\n\\n###### About\\n  * Features⟨3⟩\\n  * Pricing & Plans⟨4⟩\\n  * Documentation⟨21⟩\\n  * Jobs 1⟨25⟩\\n\\n\\n###### Community\\n  * GitHub⟨1⟩\\n  * Discord⟨24⟩\\n  * Email\\n\\n\\n###### Policies & Legal\\n  * Security⟨23⟩\\n  * Terms & Conditions⟨26⟩\\n  * Privacy policy⟨27⟩\\n  * Cookie Policy⟨28⟩\\n\\n\\n08\\n' references_markdown='\\n\\n## References\\n\\n⟨1⟩ https://hatchet.run/<https:/github.com/hatchet-dev/hatchet>:  Hatchet is fully open-source. Star us on Github\\n⟨2⟩ https://hatchet.run/_next/static/media/hatchet-logo.fcf6ba54.svg: ![Hatchet\\n⟨3⟩ https://hatchet.run/</>: Product\\n⟨4⟩ https://hatchet.run/</pricing>: Pricing\\n⟨5⟩ https://hatchet.run/<https:/docs.hatchet.run>: Documentation\\n⟨6⟩ https://hatchet.run/<https:/cloud.onhatchet.run/auth/login>: Sign In\\n⟨7⟩ https://hatchet.run/<https:/cloud.onhatchet.run/auth/register>: Get StartedGet Started\\n⟨8⟩ https://hatchet.run/</office-hours>: Meet with a Founder \\n⟨9⟩ https://hatchet.run/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fyc.6a2a28a4.png&w=3840&q=75: YCombinator\\n⟨10⟩ https://hatchet.run/<https:/docs.hatchet.run/home/features/concurrency/round-robin>: Learn More ->\\n⟨11⟩ https://hatchet.run/<https:/docs.hatchet.run/home/features/child-workflows#scattergather-workflows>: Learn More ->\\n⟨12⟩ https://hatchet.run/<https:/docs.hatchet.run/home/basics/workflows>: Learn More ->\\n⟨13⟩ https://hatchet.run/<https:/docs.hatchet.run/home/features/concurrency/overview>: View All Strategies ->\\n⟨14⟩ https://hatchet.run/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fresilience.157b83bc.png&w=750&q=75: Feature 03\\n⟨15⟩ https://hatchet.run/<https:/docs.hatchet.run/home/features/errors-and-logging>: Learn More ->\\n⟨16⟩ https://hatchet.run/<https:/docs.hatchet.run/home/features/durable-execution>: Learn More ->\\n⟨17⟩ https://hatchet.run/<https:/docs.hatchet.run/home/features/triggering-runs/cron-trigger>: Learn More ->\\n⟨18⟩ https://hatchet.run/<https:/docs.hatchet.run/home/features/triggering-runs/schedule-trigger>: Learn More ->\\n⟨19⟩ https://hatchet.run/<https:/docs.hatchet.run/home/features/concurrency/overview#setting-concurrency-on-workers>: Learn More ->\\n⟨20⟩ https://hatchet.run/<https:/docs.hatchet.run/home/features/streaming>: Learn More ->\\n⟨21⟩ https://hatchet.run/<https:/docs.hatchet.run/>: Read the Docs\\n⟨22⟩ https://hatchet.run/<https:/github.com/hatchet-dev/hatchet-python-quickstart/tree/main/simple-examples/src/dag>: View Python Examples\\n⟨23⟩ https://hatchet.run/</security>: Learn more →\\n⟨24⟩ https://hatchet.run/<https:/discord.gg/ZMeUafwH89>: Join our Community \\n⟨25⟩ https://hatchet.run/<https:/www.ycombinator.com/companies/hatchet-2>: Jobs 1\\n⟨26⟩ https://hatchet.run/<https:/www.iubenda.com/terms-and-conditions/76608149>: Terms & Conditions\\n⟨27⟩ https://hatchet.run/<https:/www.iubenda.com/privacy-policy/76608149>: Privacy policy\\n⟨28⟩ https://hatchet.run/<https:/www.iubenda.com/privacy-policy/76608149/cookie-policy>: Cookie Policy\\n' fit_markdown='' fit_html=''",
  "generated_description": "**Hatchet Overview**\n\nFounded in 2023 and based in New York, Hatchet is a cutting-edge company that specializes in background task orchestration and visibility. As a proud member of Y Combinator Batch W24, Hatchet is reshaping how developers handle task queues and message brokers. The vision? To streamline your focus on writing background task logic, leaving the heavy lifting of infrastructure management to Hatchet.\n\n**What Does Hatchet Do?**\n\nThink of Hatchet as a distributed task queue that simplifies the process of creating resilient web applications. It tackles issues like concurrency, fairness, and durability with ease. Its features allow developers to run slow OpenAI requests as asynchronous tasks, chain complex workflows, and implement retries and timeouts to recover from failures. This means you can optimize your workflows without getting bogged down by the intricacies of the underlying infrastructure.\n\n**Key Features:**\n1. **Fault-Tolerant Architecture**: Hatchet replaces traditional message brokers, making distributed operations smoother and more reliable.\n2. **Fairness for Users**: Whether for generative AI or batch processing documents, Hatchet ensures that resources are allocated equitably across users—this is especially useful in high-demand environments.\n3. **High Throughput**: With an average startup latency of just 25ms, it promises low-latency scheduling and high throughput, essential for real-time applications.\n4. **Flexible Workflows**: Using Directed Acyclic Graphs (DAG), developers can design complex workflows that can also resume mid-job on failure.\n\n**Open-Source and Community-Centric**\n\nEmphasizing open-source collaboration, Hatchet invites the community to get involved. You can check out their [GitHub page](https://github.com/hatchet-dev/hatchet) to contribute, raise issues, or simply star the project.\n\n**Getting Started**\n\nFor developers eager to try Hatchet, the process is straightforward:\n1. **Register your functions** using the SDK available in Python, Typescript, and Go.\n2. **Start a Hatchet worker** to listen for events.\n3. **Run your tasks** by pushing events into the system.\n\nThis simplicity is designed to keep your focus on the core logic without getting lost in the technical weeds.\n\n**The Team and Support**\n\nLed by a small but dedicated team of two, with Dalton Caldwell as their Group Partner, Hatchet embodies the startup spirit—lean, focused, and innovative. They offer robust documentation and community support to help you navigate and maximize the capabilities of their platform.\n\nFor more in-depth information, visit their website at [hatchet.run](https://hatchet.run).\n\n**Final Thoughts**\n\nIn a world where background tasks can often become a bottleneck, Hatchet emerges as a powerful tool to handle orchestration with style and reliability. Its open-source approach not only democratizes access but also fosters a community of developers keen on building the next generation of resilient applications. If you’re dealing with complex background tasks, Hatchet is definitely worth a look."
}