{
  "links": "https://www.ycombinator.com/companies/chunkr",
  "name": "Chunkr",
  "headline": "Open source API service to parse complex documents",
  "batch": "W24",
  "description": "Battle-tested + highly modular vision infrastructure to convert PDFs, PPTs, Word, Excel, PNG, and JPEGs into LLM-ready data. \r\n\nWe started by building lumina.sh - where we needed to parse ~600M pages of scientific literature. The researchers didn't care - but devs wanted our ingestion pipeline. So we built chunkr instead. \r\n\nWe offer high quality layout analysis, OCR, bounding boxes, granular VLM controls, semantic chunking, and all the last mile engineering that goes into building standout AI applications. Common use-cases include RAG, and automating document workflows like invoices/medical reports -> database.",
  "activity_status": "Active",
  "website": "https://chunkr.ai/",
  "founded_date": 2023.0,
  "team_size": 3.0,
  "location": "San Francisco",
  "group_partner": "Harj Taggar",
  "group_partner_yc": "https://www.ycombinator.com/people/harj-taggar",
  "company_linkedin": null,
  "company_twitter": null,
  "tags": "industry:computer-vision; industry:open-source; industry:data-engineering; industry:enterprise-software; industry:search; location:san-francisco-bay-area",
  "founders": [
    {
      "name": "Mehul Chadda, Founder",
      "description": "Co-founder & CEO at Chunkr.\n\nI have a background in metrology and a bsc in materials engineering. I work on helping computers read documents now.",
      "linkedin": "https://www.linkedin.com/in/mehul-chadda-9157472a9/"
    },
    {
      "name": "Ishaan Kapoor, Founder",
      "description": "co-founder @ lumina",
      "linkedin": "https://linkedin.com/in/ishaan-kapoor99"
    },
    {
      "name": "Akhilesh Sharma, Founder",
      "description": "Co-Founder @ Lumina\nI am a mechanical engineer from the University of Illinois Urbana Champaign. I have experience in robotics and as a cloud solutions architect.",
      "linkedin": "https://linkedin.com/in/akhilesh-sharma-82151b1a5"
    }
  ],
  "status": true,
  "markdown": "raw_markdown='[chunkr](https://chunkr.ai/</>)\\n[0](https://chunkr.ai/<https:/github.com/lumina-ai-inc/chunkr>)[Legacy](https://chunkr.ai/<https:/legacy.chunkr.ai/>)\\n[Contact](https://chunkr.ai/<https:/cal.com/mehulc/30min>)\\n[Pricing](https://chunkr.ai/</#pricing>)\\n[Docs](https://chunkr.ai/<https:/docs.chunkr.ai>)\\nLogin\\nMenu\\nBacked by Y Combinator\\nOpen Source Document IntelligenceAPI service to convert complex documents into LLM/RAG-ready chunks\\nGet started for free\\nTechnical ManualsFinancial Reports Legal DocumentsResearch PapersMedical FilesConsulting ReportsGovernment ReportsTextbooks\\nHTML\\nMarkdown\\nSimple DevX\\nLightning fast integrationBuild stand out experiences with top-tier document parsing.Configure your pipeline with simple controls to setup the optimal balance of speed, quality, and features.\\nPythoncurl\\n```\\nfrom chunkr_ai import Chunkr\\nchunkr = Chunkr(api_key=\"your_api_key\")\\n# Start instantly with our default configurations\\ntask = chunkr.upload(\"/path/to/your/file\")\\n# Export HTML of document\\ntask.html(output_file=\"output.html\")\\n# Export markdown of document\\ntask.markdown(output_file=\"output.md\")\\n# Or customize the task for your use case (needs imports - view docs)\\ntask = chunkr.upload(\"path/to/file\", Configuration(\\n  chunk_processing=ChunkProcessing(\\n    target_length=1024\\n  ),\\n  segment_processing=SegmentProcessing(\\n    Table=GenerationConfig(\\n      html=GenerationStrategy.LLM,\\n    ),\\n    Picture=GenerationConfig(\\n      llm=\"Convert all charts to tables\"\\n    ),\\n  ),\\n  # Add more configurations here\\n))\\n```\\n\\nFeature Complete\\nYour RAG app\\'s Secret WeaponProduction-ready vision infrastructure for every use case. From word level bounding boxes to segment level custom VLM processing - we\\'ve got you covered.\\nLayout AnalysisIdentify over 11 segment types like Titles, Pictures, Tables, and List-items\\nMulti-lingual OCRWord-level OCR with multi-lingual support and auto text-layer detection\\nVLM\\'s for complex parsingPowerful defaults for tables + formulas, and custom parsing prompts for any segment\\nSemantic ChunkingSet your own chunk size, and let us handle the logic to maintain semantic integrity\\nFlexible File HandlingProcess PDFs, PPTs, Word docs & images via direct upload, URLs, or base64 \\nBuilt-in VisibilityDashboard to track ingest, view extraction results, and experiment with configurations\\nSecure & PrivateZero data retention with custom expiration times, SOC2 + HIPPA in progress\\nLast-mile handledBuilt in Rust for blazing-fast operations and high reliability - under 0.05% error rate\\nCloud-ready / Self-hostHit our API, or deploy on your own compute with our Dockers and Helm charts\\nAPI Pricing\\nSimple plans that scale with youStart with included monthly pages - then pay-as-you-go\\nFree100 credits month\\nFree/month\\n200 pages included\\nNo payment info required\\nDiscord community support\\nGet Started\\nStarter10,000 credits month\\n$50/month\\n5,000 pages included\\n$0.01 / page \\nCommunity + Email support\\nSubscribe\\nDev150,000 credits month\\n$200/month\\n25,000 pages included\\n$0.008 / page\\nPriority support channel\\nSubscribe\\nGrowth500,000 credits month\\n$500/month\\n100,000 pages included\\n$0.005 / page\\nDedicated founder support\\nSubscribe\\nEnterpriseCustomBook a call\\nCustom deployment strategy\\nHigh volume discounts\\n24/7 founder-led support\\nCustom SLAs & agreements\\nTuned to your data\\nDedicated migration support\\nOn-prem\\nBring your own compute\\nResearch0 credits \\nFree\\nNon-commercial use\\nCommunity support\\nAll features included\\nEasy to deploy\\nDocker images + Helm charts\\nPerfect for testing\\nGithub\\nCommercial License0 credits month\\nCustom/month\\nManaged by us in your cloud / Self-host\\nUnlimited pages - fixed monthly price\\nTuned to your data\\nCompliance support\\nEnterprise-grade SLAs\\n24/7 founder-led support\\nBook a Call\\n[Terms of Service](https://chunkr.ai/<https:/tidal-bar-00a.notion.site/Lumina-AI-INC-Terms-of-Service-dba-Chunkr-18aca54a00368047844dc19a93c5ed5d>)\\n© A product by Lumina AI Inc. - All rights reserved.\\n[](https://chunkr.ai/<https:/x.com/chunkrai>)[](https://chunkr.ai/<https:/github.com/lumina-ai-inc/chunkr>)[](https://chunkr.ai/<https:/www.linkedin.com/company/chunkr/>)[](https://chunkr.ai/<https:/discord.gg/XzKWFByKzW>)\\n![chunkr](https://chunkr.ai/assets/footer-text-comp-QFa-n_py.png)\\n' markdown_with_citations='chunkr⟨1⟩\\n0⟨2⟩Legacy⟨3⟩\\nContact⟨4⟩\\nPricing⟨5⟩\\nDocs⟨6⟩\\nLogin\\nMenu\\nBacked by Y Combinator\\nOpen Source Document IntelligenceAPI service to convert complex documents into LLM/RAG-ready chunks\\nGet started for free\\nTechnical ManualsFinancial Reports Legal DocumentsResearch PapersMedical FilesConsulting ReportsGovernment ReportsTextbooks\\nHTML\\nMarkdown\\nSimple DevX\\nLightning fast integrationBuild stand out experiences with top-tier document parsing.Configure your pipeline with simple controls to setup the optimal balance of speed, quality, and features.\\nPythoncurl\\n```\\nfrom chunkr_ai import Chunkr\\nchunkr = Chunkr(api_key=\"your_api_key\")\\n# Start instantly with our default configurations\\ntask = chunkr.upload(\"/path/to/your/file\")\\n# Export HTML of document\\ntask.html(output_file=\"output.html\")\\n# Export markdown of document\\ntask.markdown(output_file=\"output.md\")\\n# Or customize the task for your use case (needs imports - view docs)\\ntask = chunkr.upload(\"path/to/file\", Configuration(\\n  chunk_processing=ChunkProcessing(\\n    target_length=1024\\n  ),\\n  segment_processing=SegmentProcessing(\\n    Table=GenerationConfig(\\n      html=GenerationStrategy.LLM,\\n    ),\\n    Picture=GenerationConfig(\\n      llm=\"Convert all charts to tables\"\\n    ),\\n  ),\\n  # Add more configurations here\\n))\\n```\\n\\nFeature Complete\\nYour RAG app\\'s Secret WeaponProduction-ready vision infrastructure for every use case. From word level bounding boxes to segment level custom VLM processing - we\\'ve got you covered.\\nLayout AnalysisIdentify over 11 segment types like Titles, Pictures, Tables, and List-items\\nMulti-lingual OCRWord-level OCR with multi-lingual support and auto text-layer detection\\nVLM\\'s for complex parsingPowerful defaults for tables + formulas, and custom parsing prompts for any segment\\nSemantic ChunkingSet your own chunk size, and let us handle the logic to maintain semantic integrity\\nFlexible File HandlingProcess PDFs, PPTs, Word docs & images via direct upload, URLs, or base64 \\nBuilt-in VisibilityDashboard to track ingest, view extraction results, and experiment with configurations\\nSecure & PrivateZero data retention with custom expiration times, SOC2 + HIPPA in progress\\nLast-mile handledBuilt in Rust for blazing-fast operations and high reliability - under 0.05% error rate\\nCloud-ready / Self-hostHit our API, or deploy on your own compute with our Dockers and Helm charts\\nAPI Pricing\\nSimple plans that scale with youStart with included monthly pages - then pay-as-you-go\\nFree100 credits month\\nFree/month\\n200 pages included\\nNo payment info required\\nDiscord community support\\nGet Started\\nStarter10,000 credits month\\n$50/month\\n5,000 pages included\\n$0.01 / page \\nCommunity + Email support\\nSubscribe\\nDev150,000 credits month\\n$200/month\\n25,000 pages included\\n$0.008 / page\\nPriority support channel\\nSubscribe\\nGrowth500,000 credits month\\n$500/month\\n100,000 pages included\\n$0.005 / page\\nDedicated founder support\\nSubscribe\\nEnterpriseCustomBook a call\\nCustom deployment strategy\\nHigh volume discounts\\n24/7 founder-led support\\nCustom SLAs & agreements\\nTuned to your data\\nDedicated migration support\\nOn-prem\\nBring your own compute\\nResearch0 credits \\nFree\\nNon-commercial use\\nCommunity support\\nAll features included\\nEasy to deploy\\nDocker images + Helm charts\\nPerfect for testing\\nGithub\\nCommercial License0 credits month\\nCustom/month\\nManaged by us in your cloud / Self-host\\nUnlimited pages - fixed monthly price\\nTuned to your data\\nCompliance support\\nEnterprise-grade SLAs\\n24/7 founder-led support\\nBook a Call\\nTerms of Service⟨7⟩\\n© A product by Lumina AI Inc. - All rights reserved.\\n[](https://chunkr.ai/<https:/x.com/chunkrai>)[](https://chunkr.ai/<https:/github.com/lumina-ai-inc/chunkr>)[](https://chunkr.ai/<https:/www.linkedin.com/company/chunkr/>)[](https://chunkr.ai/<https:/discord.gg/XzKWFByKzW>)\\n![chunkr⟨8⟩]\\n' references_markdown='\\n\\n## References\\n\\n⟨1⟩ https://chunkr.ai/</>: chunkr\\n⟨2⟩ https://chunkr.ai/<https:/github.com/lumina-ai-inc/chunkr>: 0\\n⟨3⟩ https://chunkr.ai/<https:/legacy.chunkr.ai/>: Legacy\\n⟨4⟩ https://chunkr.ai/<https:/cal.com/mehulc/30min>: Contact\\n⟨5⟩ https://chunkr.ai/</#pricing>: Pricing\\n⟨6⟩ https://chunkr.ai/<https:/docs.chunkr.ai>: Docs\\n⟨7⟩ https://chunkr.ai/<https:/tidal-bar-00a.notion.site/Lumina-AI-INC-Terms-of-Service-dba-Chunkr-18aca54a00368047844dc19a93c5ed5d>: Terms of Service\\n⟨8⟩ https://chunkr.ai/assets/footer-text-comp-QFa-n_py.png: chunkr\\n' fit_markdown='' fit_html=''",
  "generated_description": "**Chunkr: Simplifying Document Processing**\n\nFounded in 2023 and nestled in the heart of San Francisco, Chunkr is an innovative startup emerging from Y Combinator’s Winter 2024 batch. With a keen mission to democratize access to document intelligence, Chunkr offers an open-source API service designed to convert complex documents into LLM-ready formats. This means you can take all sorts of documents—think PDFs, Word files, PowerPoints, or even images—and seamlessly parse them into a format that's ready for machine learning and AI applications.\n\n### The Story Behind Chunkr\n\nThe seed for Chunkr was planted through an earlier project called lumina.sh, born out of the need to parse an astonishing 600 million pages of scientific literature. Interestingly, while researchers had minimal interest in our parsing capabilities, software developers lined up to learn about our ingestion pipeline. This developer-centric feedback ultimately inspired the creation of Chunkr—a highly modular and efficient infrastructure for document parsing.\n\n### What We Offer\n\nChunkr stands out by providing:\n- **High-Quality Layout Analysis**: Identify and categorize document segments like titles, tables, pictures, and lists.\n- **Multi-Lingual OCR**: Extract text across languages, making it versatile for global applications.\n- **Semantic Chunking**: Maintain the context and meaning within chunks of data, ensuring AI models can interpret it effectively.\n- **Flexible File Handling**: Process various document formats, whether they are uploaded directly, served via URLs, or converted into base64.\n- **Last-Mile Engineering**: Built on Rust, Chunkr operates with exceptional speed and reliability, boasting an error rate of under 0.05%.\n\n### Use Cases\n\nChunkr enables applications ranging from rapid automated document workflows—like converting invoices or medical reports into structured databases—to powering document retrieval systems (RAG) for research or enterprise needs.\n\n### Pricing Structure\n\nChunkr offers a scalable pricing model beginning with a free tier (100 credits/month for 200 pages) to meet the needs of developers and enterprises alike. Plans increase in credits based on usage, allowing for flexibility as your document processing needs grow.\n\n### Team and Support\n\nWith a nimble team of three and guided by Group Partner Harj Taggar of Y Combinator, Chunkr is positioned to deliver dedicated and responsive support, whether through community channels or personalized enterprise solutions.\n\n### Conclusion\n\nChunkr is not just a tool; it’s a comprehensive solution for anyone looking to take advantage of the immense data locked within complex documents. If you’re a developer looking to integrate cutting-edge document processing capabilities into your AI applications, or an enterprise wanting to streamline workflows, Chunkr is ready to help. Dive into the details on their [website](https://chunkr.ai/). \n\nIn essence, Chunkr embodies the spirit of modern document intelligence—agile, open-source, and designed to harness the power of automated data processing."
}