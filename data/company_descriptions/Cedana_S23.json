{
  "links": "https://www.ycombinator.com/companies/cedana",
  "name": "Cedana",
  "headline": "Save, migrate and resume compute jobs in real-time",
  "batch": "S23",
  "description": "Cedana (YC S23) enables real-time save, move and restore for compute workloads.  We expand GPU capacity, increase reliability, reduce latency up to 10x and increase CPU/GPU utilization up to 5x resulting in significant cost savings. OpenAI, Meta and Microsoft have flavors of these capabilities internally and we’re bringing them to everyone. \r\n\nOur solution applies to AI training and inference, HPC, data analysis, dev tools and infra.  Our vision is to transform cloud compute into a real-time, arbitraged commodity. \r\n\nWe are a fully distributed remote company.  \r\n\nhttps://www.cedana.ai",
  "activity_status": "Active",
  "website": "https://cedana.ai",
  "founded_date": 2023.0,
  "team_size": 5.0,
  "location": "New York",
  "group_partner": "Garry Tan",
  "group_partner_yc": "https://www.ycombinator.com/people/garry-tan",
  "company_linkedin": null,
  "company_twitter": null,
  "tags": "industry:artificial-intelligence; industry:deep-learning; industry:developer-tools; industry:cloud-computing; industry:infrastructure; location:new-york",
  "founders": [
    {
      "name": "Neel Master, Founder",
      "description": "CEO of Cedana. Previously  CEO/co-founder of Engooden, AI-powered chronic disease management  proven to improves outcomes and lower costs for patients (Series B).  VP of Corp Development for Petra Systems  (predictive smart grid/solar company) scaled from $0-$70M ARR.  At TL Ventures ($1.6B VC fund) investing across semi, software and systems.  Built a system for large-scale, automated ML and computer vision at MIT CSAIL.  Patents and publications in AI, computer vision.",
      "linkedin": "https://www.linkedin.com/in/neelmaster1"
    },
    {
      "name": "Niranjan Ravichandra, Founder",
      "description": null,
      "linkedin": "linkedin.com/in/niranjanravichandra"
    }
  ],
  "status": true,
  "markdown": "raw_markdown='[](https://cedana.ai/</>)\\nProduct\\n[How It Works](https://cedana.ai/</product/how-it-works>)[Performance](https://cedana.ai/</product/performance>)[Orchestration](https://cedana.ai/</product/orchestration>)[Reliability](https://cedana.ai/</product/reliability>)\\nCompany\\n[About](https://cedana.ai/</about>)[Careers](https://cedana.ai/<https:/www.linkedin.com/company/cedanacorp/jobs>)[Insights](https://cedana.ai/</blog-post>)\\n[Docs](https://cedana.ai/<https:/docs.cedana.ai/>)[Request API access](https://cedana.ai/<https:/calendly.com/neel-cedana-ai/30-min-pst-clone>)\\n# Snapshot and migrate your workloads across instances\\n# Command your compute_reduce|\\n# Command your\\n# compute \\n[VIEW DOCS](https://cedana.ai/<https:/docs.cedana.ai/>)[REQUEST API ACCESS](https://cedana.ai/</connect>)\\n## Why Cedana? \\n### Reduce compute costs up to \\n![](https://cdn.prod.website-files.com/673bab08b9ca68895eda471f/673bab08b9ca68895eda474a_illustarion-2.svg)\\nEliminate idle compute. Automatically suspend and resume your workloads based on activity. Automatically bin-packs containers freeing up resources. \\n### Automated stateful failover\\n![](https://cdn.prod.website-files.com/673bab08b9ca68895eda471f/673bab08b9ca68895eda474b_illustarion.svg)\\nUpon hardware or OOM failure, automatically resume workload on a new instance without losing work.\\n### Reduce latency 2-10x \\nAccelerate cold start and time to first token by resuming your CPU/GPU workload from its previous state. Eliminate boot time, initialization, and other steps.\\n## Use Cases\\n[KUBERNETES](https://cedana.ai/<#w-tabs-0-data-w-pane-0>)[GPU ORCHESTRATION](https://cedana.ai/<#w-tabs-0-data-w-pane-1>)[AI INFERENCE](https://cedana.ai/<#w-tabs-0-data-w-pane-2>)[AI TRAINING](https://cedana.ai/<#w-tabs-0-data-w-pane-3>)[DATA WORKFLOWS](https://cedana.ai/<#w-tabs-0-data-w-pane-4>)[AI AGENTS](https://cedana.ai/<#w-tabs-0-data-w-pane-5>)[GAMING](https://cedana.ai/<#w-tabs-0-data-w-pane-6>)[HPC](https://cedana.ai/<#w-tabs-0-data-w-pane-7>)[DATABASES](https://cedana.ai/<#w-tabs-0-data-w-pane-8>)\\n#### Seamless stateful workload management for Kubernetes.\\n  * Native Kubernetes integration, seamless at all levels\\n\\n\\n  * 20-80% lower compute costs\\n  * 2-10x faster cold starts\\n  * Zero-downtime OS/HW upgrades\\n  * Automatic stateful workload failover\\n\\n\\n#### Maximize value and reliability with automated GPU orchestration.\\n  * 20%-80% increase in utilization\\n  * GPU live migration\\n  * Low-latency, elastic scaling\\n  * Automatic workload failover\\n  * Zero-downtime OS/HW upgrades\\n  * Dynamically resize workloads onto optimal\\n  * instances without interruption\\n\\n\\n#### Give your customers the highest performance, fastest, lowest-cost inferencing. Deliver enterprise SLAs.\\n  * 2-10x faster time-to-first token\\n  * Dynamically resize workloads to optimal instances\\n\\n\\n  * Automatically reduce idle inferencing time\\n  * Use spot instances without interruption\\n  * Faster model hotswapping\\n\\n\\n#### Increase throughput, reliability and speed of advanced large model training\\n  * Real-time checkpoint/restore of multi-node systems\\n\\n\\n  * Automatic workload failover always preserves work in mini-batch\\n\\n\\n  * Fully transparent, no code modifications\\n  * Fine-grained system-level checkpointing\\n  * 20%-80% lower compute costs\\n  * High availability and reliability, swap in GPUs and nodes on failure\\n\\n\\n#### Increase automation, throughput, and reliability of your workflow orchestration\\n  * Increase workload throughput\\n  * Automate workflows conditionally based on time and success criteria\\n\\n\\n  * Reduce redundant compute\\n  * Reduce manual intervention\\n  * Implement step-level retries\\n\\n\\n#### Orchestrate agent inferencing and training autonomously. Maximize utilization, reliability, and performance.\\n  * Increase GPU utilization with efficient hot swapping and bin-packing\\n\\n\\n  * Dynamic scaling for\\n    * Larger models\\n    * Increasing task complexity, context windows, and agent counts\\n    * Variable workload demands\\n\\n\\n  * Persistent agent state\\n\\n\\n#### Improve the performance and reliability of your gaming infrastructure\\n  * Reduce latency by migrating workloads to player geographies\\n\\n\\n  * Load balance workloads to eliminate resource bottlenecks\\n\\n\\n  * Automated workload failover\\n  * Zero-downtime OS/HW upgrades.\\n  * Reduce Costs 20%-80%\\n\\n\\n#### Increase automation, throughput, and reliability of your HPC workloads.\\n  * Never lose work on long-running workloads\\n  * Schedule, queue, and prioritize workloads across users and groups dynamically\\n\\n\\n  * 20-80% lower compute costs\\n  * Increase workload throughput\\n  * Automate workflows conditionally based on time and success criteria\\n\\n\\n#### Transform database deployment and operations with zero downtime migration\\n  * Live migration of in-memory databases\\n  * Zero-downtime OS/HW upgrades\\n  * Dynamically resize workloads to optimal instances\\n\\n\\n  * Eliminate over-provisioning\\n  * Automatically reduce idle compute\\n\\n\\n![](https://cdn.prod.website-files.com/62434fa732124a0fb112aab4/62434fa732124a91e612aae8_quote-mark.svg)\\n\"We reduced our cloud costs 50% by integrating Cedana\\'s Save, Migrate, and Resume capability into our product. If an instance fails, workloads automatically continue without losing work.\"\\n![](https://cdn.prod.website-files.com/673bab08b9ca68895eda471f/673be331e89725173738c320_673096fb7ef9f305b4d617ab_debo_photo.png)\\nDebo Ray\\nCEO, DevZero\\n## Easy Integration\\nUse Cedana\\'s REST API to checkpoint your application’s state, transfer it to a new instance, cloud or resource, and resume operations. No code modifications needed.\\nCheckpoint\\n[Copy to clipboard](https://cedana.ai/<#>)\\ncurl -X POST -H \"Content-Type: application/json\" -d \\'{ \"checkpoint_data\": { \"container_name\": \"$CHECKPOINT_CONTAINER\", \"sandbox_name\": \"$CHECKPOINT_SANDBOX\", \"namespace\": \"$NAMESPACE\", \"checkpoint_path\": \"$CHECKPOINT_PATH\", \"root\": \"$ROOT\" }}\\' http://$CONTROLLER_URL:1324/checkpoint\\nRestore\\n[Copy to clipboard](https://cedana.ai/<#>)\\ncurl -X POST -H \"Content-Type: application/json\" -d \\'{ \"checkpoint_data\": { \"container_name\": \"$CHECKPOINT_CONTAINER\", \"sandbox_name\": \"$CHECKPOINT_SANDBOX\", \"namespace\": \"$NAMESPACE\", \"checkpoint_path\": \"$CHECKPOINT_PATH\", \"root\": \"$ROOT\" }}\\' http://$CONTROLLER_URL:1324/restore\\n## Get started\\n### Play in the sandbox\\nWe’ve deployed a test cluster for you to play with where you can interact and experiment with the system.\\n[Sandbox](https://cedana.ai/<https:/docs.cedana.ai/sandbox-and-demo-environment>)\\n### Get a demo\\nLearn more about how Cedana is transforming compute orchestration and how we can help your organization.\\n[Connect](https://cedana.ai/</connect>)\\n### API Reference & Guides\\nFrom deploying on your cluster, to market, to GPU Checkpointing, learn our system and get started quickly.\\n[VIEW DOCS](https://cedana.ai/<https:/docs.cedana.ai>)\\nBackers / Partners\\n![](https://cdn.prod.website-files.com/673bab08b9ca68895eda471f/673bab08b9ca68895eda4770_partners_logo.svg)![](https://cdn.prod.website-files.com/673bab08b9ca68895eda471f/673bab08b9ca68895eda4772_partners_logo-1.svg)![](https://cdn.prod.website-files.com/673bab08b9ca68895eda471f/673bab08b9ca68895eda4771_partners_logo-2.svg)\\n## command your compute_ \\nThank you! Your submission has been received!\\nOops! Something went wrong while submitting the form.\\nSitemap\\n[Home](https://cedana.ai/</>)[About](https://cedana.ai/</about>)[Careers](https://cedana.ai/<https:/www.greenhouse.com/>)[Insights](https://cedana.ai/</blog-post>)[Docs](https://cedana.ai/<https:/docs.cedana.ai/>)[Get Access](https://cedana.ai/</connect>)[GitHub](https://cedana.ai/<https:/github.com/cedana>)\\nProduct\\n[How It Works](https://cedana.ai/</product/how-it-works>)[Performance](https://cedana.ai/</product/performance>)[Orchestration](https://cedana.ai/</product/orchestration>)[Reliability](https://cedana.ai/</product/reliability>)\\nSocial\\n[X](https://cedana.ai/<https:/x.com/cedanacorp>)[LinkedIn](https://cedana.ai/<https:/www.linkedin.com/company/cedanacorp>)\\n![](https://cdn.prod.website-files.com/673bab08b9ca68895eda471f/673bab08b9ca68895eda47b4_cedana_logo_footer2.svg)\\n© 2024 Cedana Systems Inc.\\n[Privacy](https://cedana.ai/</privacy-policy>)\\n' markdown_with_citations='[](https://cedana.ai/</>)\\nProduct\\nHow It Works⟨1⟩Performance⟨2⟩Orchestration⟨3⟩Reliability⟨4⟩\\nCompany\\nAbout⟨5⟩Careers⟨6⟩Insights⟨7⟩\\nDocs⟨8⟩Request API access⟨9⟩\\n# Snapshot and migrate your workloads across instances\\n# Command your compute_reduce|\\n# Command your\\n# compute \\nVIEW DOCS⟨8⟩REQUEST API ACCESS⟨10⟩\\n## Why Cedana? \\n### Reduce compute costs up to \\n![](https://cdn.prod.website-files.com/673bab08b9ca68895eda471f/673bab08b9ca68895eda474a_illustarion-2.svg)\\nEliminate idle compute. Automatically suspend and resume your workloads based on activity. Automatically bin-packs containers freeing up resources. \\n### Automated stateful failover\\n![](https://cdn.prod.website-files.com/673bab08b9ca68895eda471f/673bab08b9ca68895eda474b_illustarion.svg)\\nUpon hardware or OOM failure, automatically resume workload on a new instance without losing work.\\n### Reduce latency 2-10x \\nAccelerate cold start and time to first token by resuming your CPU/GPU workload from its previous state. Eliminate boot time, initialization, and other steps.\\n## Use Cases\\nKUBERNETES⟨11⟩GPU ORCHESTRATION⟨12⟩AI INFERENCE⟨13⟩AI TRAINING⟨14⟩DATA WORKFLOWS⟨15⟩AI AGENTS⟨16⟩GAMING⟨17⟩HPC⟨18⟩DATABASES⟨19⟩\\n#### Seamless stateful workload management for Kubernetes.\\n  * Native Kubernetes integration, seamless at all levels\\n\\n\\n  * 20-80% lower compute costs\\n  * 2-10x faster cold starts\\n  * Zero-downtime OS/HW upgrades\\n  * Automatic stateful workload failover\\n\\n\\n#### Maximize value and reliability with automated GPU orchestration.\\n  * 20%-80% increase in utilization\\n  * GPU live migration\\n  * Low-latency, elastic scaling\\n  * Automatic workload failover\\n  * Zero-downtime OS/HW upgrades\\n  * Dynamically resize workloads onto optimal\\n  * instances without interruption\\n\\n\\n#### Give your customers the highest performance, fastest, lowest-cost inferencing. Deliver enterprise SLAs.\\n  * 2-10x faster time-to-first token\\n  * Dynamically resize workloads to optimal instances\\n\\n\\n  * Automatically reduce idle inferencing time\\n  * Use spot instances without interruption\\n  * Faster model hotswapping\\n\\n\\n#### Increase throughput, reliability and speed of advanced large model training\\n  * Real-time checkpoint/restore of multi-node systems\\n\\n\\n  * Automatic workload failover always preserves work in mini-batch\\n\\n\\n  * Fully transparent, no code modifications\\n  * Fine-grained system-level checkpointing\\n  * 20%-80% lower compute costs\\n  * High availability and reliability, swap in GPUs and nodes on failure\\n\\n\\n#### Increase automation, throughput, and reliability of your workflow orchestration\\n  * Increase workload throughput\\n  * Automate workflows conditionally based on time and success criteria\\n\\n\\n  * Reduce redundant compute\\n  * Reduce manual intervention\\n  * Implement step-level retries\\n\\n\\n#### Orchestrate agent inferencing and training autonomously. Maximize utilization, reliability, and performance.\\n  * Increase GPU utilization with efficient hot swapping and bin-packing\\n\\n\\n  * Dynamic scaling for\\n    * Larger models\\n    * Increasing task complexity, context windows, and agent counts\\n    * Variable workload demands\\n\\n\\n  * Persistent agent state\\n\\n\\n#### Improve the performance and reliability of your gaming infrastructure\\n  * Reduce latency by migrating workloads to player geographies\\n\\n\\n  * Load balance workloads to eliminate resource bottlenecks\\n\\n\\n  * Automated workload failover\\n  * Zero-downtime OS/HW upgrades.\\n  * Reduce Costs 20%-80%\\n\\n\\n#### Increase automation, throughput, and reliability of your HPC workloads.\\n  * Never lose work on long-running workloads\\n  * Schedule, queue, and prioritize workloads across users and groups dynamically\\n\\n\\n  * 20-80% lower compute costs\\n  * Increase workload throughput\\n  * Automate workflows conditionally based on time and success criteria\\n\\n\\n#### Transform database deployment and operations with zero downtime migration\\n  * Live migration of in-memory databases\\n  * Zero-downtime OS/HW upgrades\\n  * Dynamically resize workloads to optimal instances\\n\\n\\n  * Eliminate over-provisioning\\n  * Automatically reduce idle compute\\n\\n\\n![](https://cdn.prod.website-files.com/62434fa732124a0fb112aab4/62434fa732124a91e612aae8_quote-mark.svg)\\n\"We reduced our cloud costs 50% by integrating Cedana\\'s Save, Migrate, and Resume capability into our product. If an instance fails, workloads automatically continue without losing work.\"\\n![](https://cdn.prod.website-files.com/673bab08b9ca68895eda471f/673be331e89725173738c320_673096fb7ef9f305b4d617ab_debo_photo.png)\\nDebo Ray\\nCEO, DevZero\\n## Easy Integration\\nUse Cedana\\'s REST API to checkpoint your application’s state, transfer it to a new instance, cloud or resource, and resume operations. No code modifications needed.\\nCheckpoint\\nCopy to clipboard⟨20⟩\\ncurl -X POST -H \"Content-Type: application/json\" -d \\'{ \"checkpoint_data\": { \"container_name\": \"$CHECKPOINT_CONTAINER\", \"sandbox_name\": \"$CHECKPOINT_SANDBOX\", \"namespace\": \"$NAMESPACE\", \"checkpoint_path\": \"$CHECKPOINT_PATH\", \"root\": \"$ROOT\" }}\\' http://$CONTROLLER_URL:1324/checkpoint\\nRestore\\nCopy to clipboard⟨20⟩\\ncurl -X POST -H \"Content-Type: application/json\" -d \\'{ \"checkpoint_data\": { \"container_name\": \"$CHECKPOINT_CONTAINER\", \"sandbox_name\": \"$CHECKPOINT_SANDBOX\", \"namespace\": \"$NAMESPACE\", \"checkpoint_path\": \"$CHECKPOINT_PATH\", \"root\": \"$ROOT\" }}\\' http://$CONTROLLER_URL:1324/restore\\n## Get started\\n### Play in the sandbox\\nWe’ve deployed a test cluster for you to play with where you can interact and experiment with the system.\\nSandbox⟨21⟩\\n### Get a demo\\nLearn more about how Cedana is transforming compute orchestration and how we can help your organization.\\nConnect⟨10⟩\\n### API Reference & Guides\\nFrom deploying on your cluster, to market, to GPU Checkpointing, learn our system and get started quickly.\\nVIEW DOCS⟨22⟩\\nBackers / Partners\\n![](https://cdn.prod.website-files.com/673bab08b9ca68895eda471f/673bab08b9ca68895eda4770_partners_logo.svg)![](https://cdn.prod.website-files.com/673bab08b9ca68895eda471f/673bab08b9ca68895eda4772_partners_logo-1.svg)![](https://cdn.prod.website-files.com/673bab08b9ca68895eda471f/673bab08b9ca68895eda4771_partners_logo-2.svg)\\n## command your compute_ \\nThank you! Your submission has been received!\\nOops! Something went wrong while submitting the form.\\nSitemap\\nHome⟨23⟩About⟨5⟩Careers⟨24⟩Insights⟨7⟩Docs⟨8⟩Get Access⟨10⟩GitHub⟨25⟩\\nProduct\\nHow It Works⟨1⟩Performance⟨2⟩Orchestration⟨3⟩Reliability⟨4⟩\\nSocial\\nX⟨26⟩LinkedIn⟨27⟩\\n![](https://cdn.prod.website-files.com/673bab08b9ca68895eda471f/673bab08b9ca68895eda47b4_cedana_logo_footer2.svg)\\n© 2024 Cedana Systems Inc.\\nPrivacy⟨28⟩\\n' references_markdown='\\n\\n## References\\n\\n⟨1⟩ https://cedana.ai/</product/how-it-works>: How It Works\\n⟨2⟩ https://cedana.ai/</product/performance>: Performance\\n⟨3⟩ https://cedana.ai/</product/orchestration>: Orchestration\\n⟨4⟩ https://cedana.ai/</product/reliability>: Reliability\\n⟨5⟩ https://cedana.ai/</about>: About\\n⟨6⟩ https://cedana.ai/<https:/www.linkedin.com/company/cedanacorp/jobs>: Careers\\n⟨7⟩ https://cedana.ai/</blog-post>: Insights\\n⟨8⟩ https://cedana.ai/<https:/docs.cedana.ai/>: Docs\\n⟨9⟩ https://cedana.ai/<https:/calendly.com/neel-cedana-ai/30-min-pst-clone>: Request API access\\n⟨10⟩ https://cedana.ai/</connect>: REQUEST API ACCESS\\n⟨11⟩ https://cedana.ai/<#w-tabs-0-data-w-pane-0>: KUBERNETES\\n⟨12⟩ https://cedana.ai/<#w-tabs-0-data-w-pane-1>: GPU ORCHESTRATION\\n⟨13⟩ https://cedana.ai/<#w-tabs-0-data-w-pane-2>: AI INFERENCE\\n⟨14⟩ https://cedana.ai/<#w-tabs-0-data-w-pane-3>: AI TRAINING\\n⟨15⟩ https://cedana.ai/<#w-tabs-0-data-w-pane-4>: DATA WORKFLOWS\\n⟨16⟩ https://cedana.ai/<#w-tabs-0-data-w-pane-5>: AI AGENTS\\n⟨17⟩ https://cedana.ai/<#w-tabs-0-data-w-pane-6>: GAMING\\n⟨18⟩ https://cedana.ai/<#w-tabs-0-data-w-pane-7>: HPC\\n⟨19⟩ https://cedana.ai/<#w-tabs-0-data-w-pane-8>: DATABASES\\n⟨20⟩ https://cedana.ai/<#>: Copy to clipboard\\n⟨21⟩ https://cedana.ai/<https:/docs.cedana.ai/sandbox-and-demo-environment>: Sandbox\\n⟨22⟩ https://cedana.ai/<https:/docs.cedana.ai>: VIEW DOCS\\n⟨23⟩ https://cedana.ai/</>: Home\\n⟨24⟩ https://cedana.ai/<https:/www.greenhouse.com/>: Careers\\n⟨25⟩ https://cedana.ai/<https:/github.com/cedana>: GitHub\\n⟨26⟩ https://cedana.ai/<https:/x.com/cedanacorp>: X\\n⟨27⟩ https://cedana.ai/<https:/www.linkedin.com/company/cedanacorp>: LinkedIn\\n⟨28⟩ https://cedana.ai/</privacy-policy>: Privacy\\n' fit_markdown='' fit_html=''",
  "generated_description": "**Cedana Overview**\n\nCedana, founded in 2023 and a participant of Y Combinator's Summer 2023 batch, is on a bold mission: to \"Save, migrate and resume compute jobs in real-time.\" Headquartered in New York and operating as a fully distributed remote team of five, Cedana is stepping into a space that has seen significant interest from tech giants like OpenAI, Meta, and Microsoft, aiming to democratize access to sophisticated compute capabilities.\n\n**What They Do**\n\nCedana's core offering addresses the inefficiencies in cloud computing by enabling real-time saving, moving, and restoring of compute workloads. This approach not only expands GPU capacity and increases reliability but also reduces latency by up to ten times while enhancing CPU/GPU utilization by up to five times. The result? Remarkable cost savings for businesses leveraging cloud services for AI training, inference, high-performance computing (HPC), and data analysis, among other applications.\n\n**Product Features and Use Cases**\n\nThe company's technology boasts powerful features that make it a standout solution:\n- **Automated State Management**: This ensures that compute workloads automatically resume on new instances without data loss upon failures.\n- **Latency Reduction**: Cold starts are accelerated significantly, enhancing the speed of CPU/GPU workloads.\n- **Cost Efficiency**: Businesses can reduce their compute expenses by 20%-80%, primarily by eliminating idle resources through active workload management.\n\nCedana's capabilities find applications across various sectors, including:\n- Kubernetes workload management\n- GPU orchestration for improved utilization\n- AI inference and training\n- Advanced data workflows\n- Gaming and HPC applications\n\n**Vision and Future**\n\nCedana aspires to transform cloud computing into a real-time, arbitraged commodity, making sophisticated computing power accessible to smaller enterprises that previously had to rely on larger providers. This vision is supported by an easy integration model using their REST API, which allows users to checkpoint and migrate workloads with no code changes needed.\n\nBacked by renowned partners and led by an experienced team, Cedana stands ready to carve out a significant space in the cloud computing landscape, focusing on enhancing reliability and performance while cutting costs. \n\nFor more information and to see how Cedana can enhance your compute capabilities, you can visit [Cedana's website](https://www.cedana.ai)."
}