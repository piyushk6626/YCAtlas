{
  "links": "https://www.ycombinator.com/companies/felafax",
  "name": "Felafax",
  "headline": "Building AI Infra for non-NVIDIA GPUs",
  "batch": "S24",
  "description": "Felafax is building AI infra for non-NVIDIA GPUs. With our ML experience from Google and Meta, we built a new AI stack that is 2x more cost-efficient and performant without needing Nvidia‚Äôs CUDA.",
  "activity_status": "Active",
  "website": "https://felafax.ai",
  "founded_date": 2024.0,
  "team_size": 2.0,
  "location": "San Francisco",
  "group_partner": "David Lieb",
  "group_partner_yc": "https://www.ycombinator.com/people/david-lieb",
  "company_linkedin": null,
  "company_twitter": null,
  "tags": "industry:artificial-intelligence; industry:generative-ai; industry:infrastructure; industry:ai; location:san-francisco-bay-area",
  "founders": [
    {
      "name": "Nithin Sonti, Founder",
      "description": "Building AI Infra for non-NVIDIA GPUs and democratizing large-scale AI training!\n\nPreviously, ML Engineer at Google/Youtube and NVIDIA.",
      "linkedin": "https://www.linkedin.com/in/nithinsonti"
    },
    {
      "name": "Nikhil Sonti, Founder",
      "description": "Building AI Infra for non-NVIDIA GPUs. Previously, spent over 6 years at Meta, worked on ML inference infra for serving ranking models for Newsfeed, Reels, and Watch. Before that, worked at Microsoft for 3 years.",
      "linkedin": "https://www.linkedin.com/in/nikhilvenkatsonti"
    }
  ],
  "status": true,
  "markdown": "raw_markdown=\"[![Blinder logo](https://felafax.ai/felafax.svg)](https://felafax.ai/</>)\\n  * [Features](https://felafax.ai/</#features>)\\n  * [Contact](https://felafax.ai/</#contact>)\\n  * [Team](https://felafax.ai/</#team>)\\n  * [Blog](https://felafax.ai/</blogs>)\\n\\n\\n# Enterprise AI Platform. Simple. Scalable. Open.\\nFelafax‚Äôs AI platform runs on any accelerator‚Äîfrom Google TPU to AWS Trainium, NVIDIA to AMD‚Äîachieving 2X cost-efficiency without sacrificing performance.\\n[Request Access](https://felafax.ai/<https:/tally.so/r/mRLeaQ>)[Schedule Demo](https://felafax.ai/<https:/cal.com/nikhilsv/meet>)\\n![Felafax Demo](https://felafax.ai/felafax-demo.gif)\\n  * ![YCombinator](https://felafax.ai/_next/static/media/backed_by_yc.c9334e86.svg)\\n\\n\\n### Key Features of Felafax\\n  * #### Scale Effortlessly\\nOne-click spin-up of clusters from 8 to 1024 TPU chips. Our framework seamlessly handles training orchestration at any scale.\\n  * #### Performance at Lower Cost\\nOur custom training platform, built from the ground up, uses XLA compiler and JAX. Get H100-level performance at 30% lower cost.\\n  * #### On-prem deployment\\nWe deploy in your VPC, ensuring your data never leaves your network and remains secure and private.\\n  * #### Highly Customizable\\nUse our no-code UI for fine-tuning or drop into a Jupyter notebook to tailor your training run. Full control with zero compromises.\\n  * #### We handle all ML Ops\\nWe provide optimized model partitioning for larger models like Llama 3.1 405B, handle multi-controller training and inference. Focus on innovation, not infrastructure.\\n  * #### Out-of-the-Box Templates\\nChoose between PyTorch XLA or JAX. Get started quickly with pre-configured environments and all necessary dependencies installed.\\n\\n\\n### Want to fine-tune and deploy Llama3 in your enterprise VPC?\\nPlease reach out to us, and we'll work with you to get you set up. üôÇ\\n[Reach out](https://felafax.ai/<https:/cal.com/nikhilsv/meet>)\\n### Meet our team\\n  * ![](https://felafax.ai/_next/static/media/nikhil.a3c0ac56.jpg)\\n#### Nikhil Sonti\\nCo-Founder & CEO\\nOver 6 years at Meta and 3+ years at Microsoft, Nikhil has worked on ML inference infrastructure for Facebook Feed, focusing on performance and efficiency.\\n[](https://felafax.ai/<https:/www.linkedin.com/in/nikhil-sv/>)\\n  * ![](https://felafax.ai/_next/static/media/nithin.842eec22.jpg)\\n#### Nithin Sonti\\nCo-Founder & CTO\\nNithin has over 5 years of experience at Google and Nvidia, specializing in building large-scale ML training infrastructure. He worked on building the trainer platform for YouTube recommender models and fine-tuned Gemini for YouTube.\\n[](https://felafax.ai/<https:/www.linkedin.com/in/nithinsonti/>)\\n\\n\\n## Built by engineers with experience at\\n  * ![Google](https://felafax.ai/_next/static/media/google.a0008721.svg)\\n  * ![Facebook](https://felafax.ai/_next/static/media/facebook.86783730.svg)\\n  * ![Nvidia](https://felafax.ai/_next/static/media/nvidia.4c592dbd.svg)\\n  * ![Microsoft](https://felafax.ai/_next/static/media/microsoft.3afa1635.svg)\\n\\n\\n### Let‚Äôs connect\\nWe‚Äôre here to help and answer any questions you might have. We look forward to hearing from you.\\n  * #### Email\\nfounders@felafax.ai\\n  * #### Meeting\\n[cal.com](https://felafax.ai/<https:/cal.com/nikhilsv/meet>)\\n\\n\\n¬© 2024 Felafax. All rights reserved.\\n\" markdown_with_citations=\"![Blinder logo‚ü®1‚ü©](https://felafax.ai/</>)\\n  * Features‚ü®2‚ü©\\n  * Contact‚ü®3‚ü©\\n  * Team‚ü®4‚ü©\\n  * Blog‚ü®5‚ü©\\n\\n\\n# Enterprise AI Platform. Simple. Scalable. Open.\\nFelafax‚Äôs AI platform runs on any accelerator‚Äîfrom Google TPU to AWS Trainium, NVIDIA to AMD‚Äîachieving 2X cost-efficiency without sacrificing performance.\\nRequest Access‚ü®6‚ü©Schedule Demo‚ü®7‚ü©\\n![Felafax Demo‚ü®8‚ü©]\\n  * ![YCombinator‚ü®9‚ü©]\\n\\n\\n### Key Features of Felafax\\n  * #### Scale Effortlessly\\nOne-click spin-up of clusters from 8 to 1024 TPU chips. Our framework seamlessly handles training orchestration at any scale.\\n  * #### Performance at Lower Cost\\nOur custom training platform, built from the ground up, uses XLA compiler and JAX. Get H100-level performance at 30% lower cost.\\n  * #### On-prem deployment\\nWe deploy in your VPC, ensuring your data never leaves your network and remains secure and private.\\n  * #### Highly Customizable\\nUse our no-code UI for fine-tuning or drop into a Jupyter notebook to tailor your training run. Full control with zero compromises.\\n  * #### We handle all ML Ops\\nWe provide optimized model partitioning for larger models like Llama 3.1 405B, handle multi-controller training and inference. Focus on innovation, not infrastructure.\\n  * #### Out-of-the-Box Templates\\nChoose between PyTorch XLA or JAX. Get started quickly with pre-configured environments and all necessary dependencies installed.\\n\\n\\n### Want to fine-tune and deploy Llama3 in your enterprise VPC?\\nPlease reach out to us, and we'll work with you to get you set up. üôÇ\\nReach out‚ü®7‚ü©\\n### Meet our team\\n  * ![](https://felafax.ai/_next/static/media/nikhil.a3c0ac56.jpg)\\n#### Nikhil Sonti\\nCo-Founder & CEO\\nOver 6 years at Meta and 3+ years at Microsoft, Nikhil has worked on ML inference infrastructure for Facebook Feed, focusing on performance and efficiency.\\n[](https://felafax.ai/<https:/www.linkedin.com/in/nikhil-sv/>)\\n  * ![](https://felafax.ai/_next/static/media/nithin.842eec22.jpg)\\n#### Nithin Sonti\\nCo-Founder & CTO\\nNithin has over 5 years of experience at Google and Nvidia, specializing in building large-scale ML training infrastructure. He worked on building the trainer platform for YouTube recommender models and fine-tuned Gemini for YouTube.\\n[](https://felafax.ai/<https:/www.linkedin.com/in/nithinsonti/>)\\n\\n\\n## Built by engineers with experience at\\n  * ![Google‚ü®10‚ü©]\\n  * ![Facebook‚ü®11‚ü©]\\n  * ![Nvidia‚ü®12‚ü©]\\n  * ![Microsoft‚ü®13‚ü©]\\n\\n\\n### Let‚Äôs connect\\nWe‚Äôre here to help and answer any questions you might have. We look forward to hearing from you.\\n  * #### Email\\nfounders@felafax.ai\\n  * #### Meeting\\ncal.com‚ü®7‚ü©\\n\\n\\n¬© 2024 Felafax. All rights reserved.\\n\" references_markdown='\\n\\n## References\\n\\n‚ü®1‚ü© https://felafax.ai/felafax.svg: ![Blinder logo\\n‚ü®2‚ü© https://felafax.ai/</#features>: Features\\n‚ü®3‚ü© https://felafax.ai/</#contact>: Contact\\n‚ü®4‚ü© https://felafax.ai/</#team>: Team\\n‚ü®5‚ü© https://felafax.ai/</blogs>: Blog\\n‚ü®6‚ü© https://felafax.ai/<https:/tally.so/r/mRLeaQ>: Request Access\\n‚ü®7‚ü© https://felafax.ai/<https:/cal.com/nikhilsv/meet>: Schedule Demo\\n‚ü®8‚ü© https://felafax.ai/felafax-demo.gif: Felafax Demo\\n‚ü®9‚ü© https://felafax.ai/_next/static/media/backed_by_yc.c9334e86.svg: YCombinator\\n‚ü®10‚ü© https://felafax.ai/_next/static/media/google.a0008721.svg: Google\\n‚ü®11‚ü© https://felafax.ai/_next/static/media/facebook.86783730.svg: Facebook\\n‚ü®12‚ü© https://felafax.ai/_next/static/media/nvidia.4c592dbd.svg: Nvidia\\n‚ü®13‚ü© https://felafax.ai/_next/static/media/microsoft.3afa1635.svg: Microsoft\\n' fit_markdown='' fit_html=''",
  "generated_description": "### Felafax Overview\n\nFelafax is an innovative startup founded in 2024, based in San Francisco, and is part of Y Combinator's Batch S24. The company specializes in providing AI infrastructure that runs on non-NVIDIA GPUs, aiming to democratize access to advanced AI capabilities without the hefty price tag associated with traditional GPU platforms. With a lean team of just two founders, Felafax is leveraging deep expertise from tech giants like Google and Meta to create a more cost-effective AI stack.\n\n**Mission:**  \nFelafax is dedicated to building AI infrastructure for non-NVIDIA GPUs, specifically designed to be 2x more cost-efficient and high-performing without relying on NVIDIA's CUDA technology.\n\n### Key Features of Felafax\n\n1. **Seamless Scaling:**  \n   The platform allows one-click deployment of clusters ranging from 8 to 1024 TPU chips, streamlining the training process at any scale.\n\n2. **Cost and Performance:**  \n   Felafax's custom-built training platform utilizes the XLA compiler and JAX, offering performance on par with H100-level GPUs at 30% lower costs.\n\n3. **Secure On-Prem Deployment:**  \n   They ensure data security by deploying within your own Virtual Private Cloud (VPC), meaning your sensitive data stays put.\n\n4. **Highly Customizable Solutions:**  \n   Users can either employ a no-code UI for fine-tuning or dive into Jupyter notebooks for a more tailored training experience.\n\n5. **ML Ops Simplified:**  \n   Felafax manages the heavy lifting of ML operations, including model partitioning for larger models, allowing customers to focus on innovation rather than infrastructure.\n\n6. **Out-of-the-Box Templates:**  \n   Start quickly with pre-configured environments that come with all necessary dependencies, whether using PyTorch XLA or JAX.\n\n### The Team Behind Felafax\n\n- **Nikhil Sonti, Co-Founder & CEO:**  \n  With over six years of experience at Meta and three years at Microsoft, Nikhil has honed his skills in ML inference infrastructure and is focused on driving performance and efficiency in AI deployments.\n\n- **Nithin Sonti, Co-Founder & CTO:**  \n  Nithin brings over five years of experience from Google and Nvidia, famously working on large-scale ML training infrastructures, including efforts related to the YouTube recommender models.\n\n### Connection and Further Information\n\nFelafax is committed to building relationships with potential users and partners. If you‚Äôre interested in exploring how their platform can help you fine-tune and deploy models like Llama 3 in your enterprise VPC, they invite you to reach out. \n\n- **Website:** [felafax.ai](https://felafax.ai)\n- **Contact:** founders@felafax.ai\n- **Demo & Access:** [Request Access](https://felafax.ai/<https:/tally.so/r/mRLeaQ>) | [Schedule Demo](https://felafax.ai/<https:/cal.com/nikhilsv/meet>)\n\nIn summary, Felafax is at the forefront of a critical shift in the AI infrastructure landscape, championing accessibility and efficiency in processing power. They're an exciting team to watch as they continue to evolve and empower their users with groundbreaking tools."
}